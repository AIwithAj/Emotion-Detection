{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from src.Emotion_Detection import logger\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    testing_data: Path\n",
    "    model_chkpt: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from src.Emotion_Detection.constants import *\n",
    "from src.Emotion_Detection.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"train\")\n",
    "        testing_data= os.path.join(self.config.data_ingestion.unzip_dir, \"test\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            testing_data=Path(testing_data),\n",
    "            model_chkpt=Path(training.model_chkpt),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "        logger.info(\"TrainingConfig successfully loaded\")\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# # Log in with a different account\n",
    "# wandb.login(relogin=True)\n",
    "# run = wandb.init(\n",
    "#     project = \"intro-keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wandb.keras import WandbCallback,WandbMetricsLogger,WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Emotion_Detection.utils.common import LogConfMatrix,LogResultsTable,plot_training_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\lenovo\\\\Desktop\\\\Emotion-Detection\\\\wandb\\\\run-20240513_115255-qc2ms2xy\\\\files\\\\run-20240513_115255-qc2ms2xy\\\\files']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "# Get the base path provided by W&B\n",
    "base_path = wandb.run.dir\n",
    "\n",
    "# Example absolute path\n",
    "\n",
    "\n",
    "# Convert absolute path to relative path based on base_path\n",
    "# relative_path = os.path.relpath(absolute_path, base_path)\n",
    "\n",
    "# Save using relative path\n",
    "wandb.save(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        train_datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        train_datagenerator_ = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **train_datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=10,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                zoom_range=0.2,\n",
    "                **train_datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = train_datagenerator_\n",
    "\n",
    "\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "                                                    self.config.training_data,  # Directory containing training data\n",
    "                                                    class_mode=\"categorical\",  # Classification mode for categorical labels\n",
    "                                                    target_size=(224, 224),  # Resize input images to (224,224)\n",
    "                                                    color_mode='rgb',  # Color mode for images (RGB)\n",
    "                                                    shuffle=True,  # Shuffle training data\n",
    "                                                    batch_size=self.config.params_batch_size,  # Batch size for training\n",
    "                                                    subset='training'  # Subset of data (training)\n",
    "                                                   )\n",
    "\n",
    "        test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                  rescale=1 / 255.  # Rescale pixel values to [0,1]\n",
    "                                 )\n",
    "        self.test_generator = test_datagen.flow_from_directory(\n",
    "                                                  self.config.testing_data,  # Directory containing testing data\n",
    "                                                  class_mode=\"categorical\",  # Classification mode for categorical labels\n",
    "                                                  target_size=(224, 224),  # Resize input images to (224,224)\n",
    "                                                  color_mode=\"rgb\",  # Color mode for images (RGB)\n",
    "                                                  shuffle=False,  # Do not shuffle testing data\n",
    "                                                  batch_size=self.config.params_batch_size  # Batch size for testing\n",
    "                                                 )\n",
    "        \n",
    "                # Extract class labels for all instances in the training dataset\n",
    "        classes = np.array(self.train_generator.classes)\n",
    "\n",
    "        # Calculate class weights to handle imbalances in the training data\n",
    "        # 'balanced' mode automatically adjusts weights inversely proportional to class frequencies\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',  # Strategy to balance classes\n",
    "            classes=np.unique(classes),  # Unique class labels\n",
    "            y=classes  # Class labels for each instance in the training dataset\n",
    "        )\n",
    "\n",
    "        # Create a dictionary mapping class indices to their calculated weights\n",
    "        self.class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        # Output the class weights dictionary\n",
    "        print(\"Class Weights Dictionary:\", self.class_weights_dict)\n",
    "\n",
    "\n",
    "\n",
    "                # File path for the model checkpoint\n",
    "        cnn_path =self.config.model_chkpt\n",
    "        name = 'best_weights'\n",
    "        chk_path = os.path.join(cnn_path, name)\n",
    "\n",
    "        # Callback to save the model checkpoint\n",
    "        checkpoint = ModelCheckpoint(filepath=chk_path,\n",
    "                                    save_best_only=True,\n",
    "                                    verbose=1,\n",
    "                                    monitor='val_accuracy',\n",
    "                                    mode = 'max')\n",
    "\n",
    "        # Callback for early stopping\n",
    "        earlystop = EarlyStopping(monitor = 'val_accuracy',\n",
    "                                patience = 7,\n",
    "                                restore_best_weights = True,\n",
    "                                verbose=1)\n",
    "\n",
    "        # Callback to reduce learning rate\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                    factor=0.2,\n",
    "                                    patience=2,\n",
    "        #                             min_lr=0.00005,\n",
    "                                    verbose=1)\n",
    "\n",
    "        # Callback to log training data to a CSV file\n",
    "        csv_logger = CSVLogger(os.path.join(cnn_path,'training.log'))\n",
    "        wandb.login(relogin=True)\n",
    "        run = wandb.init(\n",
    "            project = \"intro-keras\",\n",
    "        )\n",
    "        # model_checkpoint = WandbModelCheckpoint(\n",
    "        #     filepath=r'model_artifiact/best_model',\n",
    "        #     monitor='val_accuracy',  # Monitor validation accuracy\n",
    "        #     save_weights_only=False,  # Save entire model\n",
    "        #     mode='max',  # Save when validation accuracy is maximized\n",
    "        #     save_best_only=True,  # Save only the best model\n",
    "        #     verbose=1,  # Verbosity level\n",
    "        #     filename='best_model.h5',  # Filename for saved model\n",
    "        #     log_weights=True  # Log histograms of the model's layer weights\n",
    "        # )\n",
    "\n",
    "        logger.info(\"wandb login succefully\")\n",
    "        wandb_callback = WandbCallback(\n",
    "                    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "                    save_model='best',  # Save only the best model\n",
    "                    save_model_path='best_model.h5'  # Custom name for the saved model\n",
    "                )\n",
    "        \n",
    "        # Aggregating all callbacks into a list\n",
    "        self.callbacks = [wandb_callback, earlystop, csv_logger,LogResultsTable(self.test_generator,self.model),LogConfMatrix(self.test_generator,self.model)]  # Adjusted as per your use-case\n",
    "     \n",
    "        logger.info(\"callbacks list succesfully inititated\")\n",
    "   \n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        # Log in with a different account\n",
    "\n",
    "        self.steps_per_epoch = (self.train_generator.samples // self.train_generator.batch_size)+1\n",
    "        self.test_steps_epoch = (self.test_generator.samples // self.test_generator.batch_size)+1\n",
    "        logger.info(\"training initated ....\")\n",
    "        history=self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=1,\n",
    "            validation_steps=1,\n",
    "            validation_data=self.test_generator,\n",
    "            class_weight=self.class_weights_dict,\n",
    "            callbacks=self.callbacks,\n",
    "        )\n",
    "        logger.info(\"saving model....\")\n",
    "\n",
    "        # Call the function to get the figure\n",
    "        fig = plot_training_history(history)\n",
    "\n",
    "        # Log the figure to Weights & Biases\n",
    "        wandb.log({\"training_history\": fig})\n",
    "        logger.info(\"wandb training history logged in \")\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-13 12:43:11,367: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-13 12:43:11,377: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-13 12:43:11,381: INFO: common: created directory at: artifacts]\n",
      "[2024-05-13 12:43:11,384: INFO: common: created directory at: artifacts\\training]\n",
      "[2024-05-13 12:43:11,387: INFO: 4073233030: TrainingConfig successfully loaded]\n",
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Class Weights Dictionary: {0: 1.0266046844269623, 1: 9.406618610747051, 2: 1.0010460615781582, 3: 0.5684387684387684, 4: 0.8260394187886635, 5: 0.8491274770777877, 6: 1.293372978330405}\n",
      "[2024-05-13 12:43:30,190: INFO: 3461614742: wandb login succefully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-13 12:43:30,354: INFO: 3461614742: callbacks list succesfully inititated]\n",
      "[2024-05-13 12:43:30,369: INFO: 3461614742: training initated ....]\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3384 - accuracy: 0.1562\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to model_artifiact\\best_model\n",
      "[2024-05-13 12:45:16,841: WARNING: save: Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.]\n",
      "[2024-05-13 12:45:34,831: INFO: builder_impl: Assets written to: model_artifiact\\best_model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Adding directory to artifact (.\\model_artifiact\\best_model)... Done. 8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 133s 133s/step - loss: 4.3384 - accuracy: 0.1562 - val_loss: 7.7034 - val_accuracy: 0.0000e+00\n",
      "[2024-05-13 12:45:47,618: INFO: 3461614742: saving model....]\n",
      "[2024-05-13 12:45:47,620: INFO: 3461614742: wandb training history logged in ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
